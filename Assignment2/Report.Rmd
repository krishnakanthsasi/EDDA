---
title: "Assignment 2"
output: pdf_document
---

```{r setup, include=FALSE, }
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

## Exercise 1

In this exercise, bootstrap test is used to determine whether the distribution of the data set is exponential and its $\lambda$ is between [0.01, 0.1].

```{r, fig.align='center'}
data = read.table("./data/telephone.txt", header = TRUE)

B = 2000 # Iterations times

# Bounds for rate of exponential distribution
rateLower = 0.01
rateUpper = 0.1
rateIncrease = 0.01

n = length(data$Bills)

# Setup for loop
tStar = numeric(B)
t = median(data$Bills)


hist(data$Bills, freq = FALSE, main="Histogram of Bills", xlab = "Bills")
x=seq(0, max(data$Bills), length=1000)
lines(x, dexp(x, 0.03), type = "l", col="blue", lwd=2)
```

The loop that tries values for $\lambda$ is given below. All values of $H_0: \lambda$ = [0.01, 0.1] are rejected except for $H_0: \lambda$ = 0.03. The curve for $\lambda$ = 0.03 can be seen in the first graph. However, this density curve does not look like the distribution of T* histogram. Since p-value of the $H_0: \lambda$ = 0.03 is greater than 5%, the test is inconclusive.

```{r, fig.align='center'}
# Try for all rates
for(rate in seq(from=rateLower, to=rateUpper, by=rateIncrease)) {
  for(iter in seq(from=0, to=B, by=1)) {
    # Get surrogate X*s from exponential distribution
    # with same size as the original data set
    sample = rexp(n, rate)
    
    # Store T* values for future comparison
    tStar[iter] = median(sample)
  }
  
  # Calculate p-value according to the slides of week-2
  pl = sum(tStar<t) / B
  pr = sum(tStar>t) / B
  p = 2*min(pl, pr)
  
  if (p > 0.05) {
    print(sprintf("H0: Rate: %.2f P-Value: %.2f is not rejected.", rate, p))
    break
  }
}

# Try to plot it with same graph style in week-2/30th slide
par(mfrow=c(1,1))
hist(tStar, probability=TRUE, ylim=c(0, 0.22), main="Histogram of T*", xlab = "T*")
```

## Exercise 2

```{r, echo=FALSE}
confidence = function(data) {
  B = 1000
  Tstar = numeric(B)
  
  for (i in 1:B) {
    Xstar = sample(data, replace=TRUE)
    Tstar[i] = mean(Xstar)
  }
  
  Tstar25 = quantile(Tstar, 0.025, na.rm = TRUE)
  Tstar975 = quantile(Tstar, 0.975, na.rm = TRUE)
  
  T1 = mean(data)
  sum(Tstar < Tstar25)
  c(2 * T1 - Tstar975, 2 * T1 - Tstar25)
}
```

```{r, fig.align='center'}

light = read.table("./data/light.txt") # Newcomb's measurements made in 1882 on three days
light1879 = read.table("./data/light1879.txt", fill = TRUE) # Michelson's measurements in 1879
light1882 = read.table("./data/light1882.txt", fill = TRUE) # Michelson's measurements in 1882

lightMicro = (light / 1000) + 24.8 # Microseconds to travel 7442 kilometers
light = 7442 / (lightMicro * 10^(-3)) # TODO: This should be 10^-6 but something is not right

par(mfrow=c(1,2), oma = c(0, 0, 3, 0)) # Two graphs side by side
hist(light$V1, freq=FALSE, main = "Histogram", xlab="Speed of Light (km/sec)")
boxplot(light$V1)

mtext("Newcomb's Measurements in 1882", outer = TRUE, cex = 1.3)

light1879Stacked = stack(light1879 + 299000)
light1879Stacked = light1879Stacked[complete.cases(light1879Stacked), ]
hist(light1879Stacked$values, freq=FALSE, 
     main = "Histogram", xlab="Speed of Light (km/sec)")
boxplot(light1879Stacked$values)
mtext("Michelson's Measurements in 1879", outer = TRUE, cex = 1.3)

light1882Stacked = stack(light1882 + 299000)
light1882Stacked = light1882Stacked[complete.cases(light1882Stacked), ]
hist(light1882Stacked$values, freq=FALSE
     , main = "Histogram", xlab="Speed of Light (km/sec)")
boxplot(light1882Stacked$values)
mtext("Michelson's Measurements in 1882", outer = TRUE, cex = 1.3)

```

The exact value of the speed of light in vacuum denoted by c is 299,792,458 metres/second. Confidence intervals for the given three different data sets can be seen below. Given the confidence intervals and the exact value of the speed of light, it can be said that it is consistent with the measurements of Michelson's measurements done in 1882.

```{r, echo=FALSE}
c1 = confidence(light$V1)
c2 = confidence(light1879Stacked$values)
c3 = confidence(light1882Stacked$values)

print(sprintf("Method              97.5%%    2.5%%"))
print(sprintf("Newcomb's   1882    %.3f    %.3f", c1[1], c1[2]))
print(sprintf("Michelson's 1879    %.3f    %.3f", c2[1], c2[2]))
print(sprintf("Michelson's 1882    %.3f    %.3f", c3[1], c3[2]))
```

## Exercise 3

For testing median values we used sign-test because from the graphs, the sample does not seem to have a normal distribution or from a symmetrical population. Histogram and QQ-Plot of the data set can be seen below. For the test, hypothesis $H_0: \mu \leq 31$ is tested against the alternative hypothesis, $H_1: \mu > 31$. 

```{r, fig.align='center'}
klmData = scan("./data/klm.txt")

par(mfrow=c(1,2))
# This doen't look like it is from normal distribution?
hist(klmData, freq=FALSE)
boxplot(klmData)

par(mfrow=c(1,1))
qqnorm(klmData)

```

We expect median to divide the data set into two equal parts so that when a random sample is chosen, the probability of it being smaller or greater than the median should be equal to tossing a coin.

```{r}
# H_0 median duration is <= 31 days
testMedian = 31

klmMedian = median(klmData)

sumOut = sum(klmData <= testMedian) # Get values smaller than the test value
binom.test(sumOut, length(klmData), p=0.5, alternative = "greater")

```

From the output, it can be seen that the $H_0:  \mu \leq 31$ is rejected with the p-value of 0.013 since $H_0: \mu \leq 31$ is not greater than the 50% of the sample since it is located in the first 33% of the data, therefore $H_1 \mu > 31$ is accepted.

For the seconds part of this exercise, we filtered the delivery dates which are overdue and used  binomial test with the probability of 10% since we are looking whether the deliveries are mostly made on time by Boeing without violating the criteria that is demanded by KLM.

```{r}

lateDays = sum(klmData > 72) # Days greater than max delivery days of 72
binom.test(lateDays, length(klmData), p=0.1, alternative = "greater")

```

From the output of the test, it can be seen that $H_0:d \leq 10\%$ is rejected with the p-value = 0.0056 and the alternative hypothesis $H_1:d > 10\%$ is accepted. This yiels that Boeing is failing to meet the criteria by delivering more than 10% of the parts late.

## Exercise 4

```{r, echo=FALSE}

clouds = read.table("./data/clouds.txt", header = TRUE)
sqrtClouds = sqrt(clouds)
sqrtSqrtClouds = sqrt(sqrtClouds)

```

### Section 1

```{r, fig.align='center'}

par(mfrow=c(1,2))
hist(clouds$seeded - clouds$unseeded, main = "Histogram of Cloud Differences")
qqnorm(clouds$seeded - clouds$unseeded, main = "Normal Q-Q Plot Clouds Differences")

# T - Test

# Differences of the data samples does not seem to be normal
# However, histogram of these differences is seem to be?
# This is probably not paired since QQ Normal Plot suggests that
# the distribution is not normal
t.test(clouds$seeded, clouds$unseeded)

# Mann - Whitney Test

wilcox.test(clouds$seeded, clouds$unseeded)

# Kolmogorov - Smirnov Test

ks.test(clouds$seeded, clouds$unseeded)

```

### Section 2

```{r, fig.align=TRUE}

par(mfrow=c(1,2))
hist(sqrtClouds$seeded - sqrtClouds$unseeded, main = "Histogram of Sqrt Differences")
qqnorm(sqrtClouds$seeded - sqrtClouds$unseeded, main = "Normal Q-Q Sqrt Differences")

# T - Test

t.test(sqrtClouds$seeded, sqrtClouds$unseeded)

# Mann - Whitney Test

wilcox.test(sqrtClouds$seeded, sqrtClouds$unseeded)

# Kolmogorov - Smirnov Test

ks.test(sqrtClouds$seeded, sqrtClouds$unseeded)

```

### Section 3


```{r, fig.align=TRUE}

par(mfrow=c(1,2))
hist(sqrtSqrtClouds$seeded - sqrtSqrtClouds$unseeded, main = "Histogram of SqrtSqrt Differences")
qqnorm(sqrtSqrtClouds$seeded - sqrtSqrtClouds$unseeded, main = "Normal Q-Q SqrtSqrt Differences")

# T - Test

t.test(sqrtSqrtClouds$seeded, sqrtSqrtClouds$unseeded)

# Mann - Whitney Test

wilcox.test(sqrtSqrtClouds$seeded, sqrtSqrtClouds$unseeded)

# Kolmogorov - Smirnov Test

ks.test(sqrtSqrtClouds$seeded, sqrtSqrtClouds$unseeded)

```

## Exercise 5

```{r, fig.align=TRUE}

peruvians = read.table("C:/Users/krish/Documents/EDDA/Assignment2/data/peruvians.txt", header=TRUE)
```

### Section 1

```{r. fig.align=TRUE}
par(mfrow=c(3,3))
plot(age~migration)
plot(weight~migration)
plot(length~migration)
plot(wrist~migration)
plot(systolic~migration)
plot(diastolic~migration)
```

From the plots, there seems to be a dependence between age, and weight to migration years.Apart from this none of the other variables seems to display a significant correlation to migration.

### Section 2

```{r, fig.align=TRUE}
par(mfrow=c(1,1))
# Checking normality for migration sample
qqnorm(migration,main="Q-Q Plot migration")
#Normality is not evident for migration sample, hence we use Spearman's correlation test to check for dependence between the variables

print(cor.test(age, migration, method = "spearman"))
# Moderate correlation observed

print(cor.test(weight, migration, method = "spearman"))
# Moderate correlation observed

print(cor.test(length, migration, method = "spearman"))
# Insignificant correlation

print(cor.test(wrist, migration, method = "spearman"))
# Weak correlation observed

print(cor.test(systolic, migration, method = "spearman"))
# Weak but inverse correlation observed

print(cor.test(diastolic, migration, method = "spearman"))
# Insignificant correlation observed
```

Both age and weight seems to show moderate correlation to migration. Other variables, display either insignificant or weak correlation. 

## Exercise 6